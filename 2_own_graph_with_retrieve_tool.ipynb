{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a own graph with retrieve as tool.Also using private and open LLM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "import warnings\n",
    "from IPython.display import display, Markdown  # to see better the output text\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "_ = load_dotenv(find_dotenv())  # read local .env file\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install langchain_openai\n",
    "# ! pip install langchain_ollama\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "gpt_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1)\n",
    "\n",
    "gemma_llm = ChatOllama(\n",
    "    model=\"gemma2:latest\",\n",
    "    temperature=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_MESSAGE = \"You are a helpful assistant. Answer the questions using the information retrieved\"\n",
    "NUM_RETRIEVAL_CHUNKS = 3\n",
    "NUM_HISTORY_MESSAGES = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the documents to simulate the Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain import hub\n",
    "import bs4\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"mxbai-embed-large\")\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "\n",
    "# Load and chunk contents of the blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Index chunks\n",
    "_ = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the retrieve process as a tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import StructuredTool\n",
    "from langchain_core.tools import tool\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# @tool(response_format=\"content_and_artifact\")\n",
    "\n",
    "\n",
    "class RetieveSchema(BaseModel):\n",
    "    query: str = Field(description=\"query to execute\")\n",
    "\n",
    "\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(\n",
    "        query, k=NUM_RETRIEVAL_CHUNKS)\n",
    "    content = \"\\n\\n\".join(\n",
    "        # it's important to keep the metadata to know the source of the retrieved content\n",
    "        (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return content\n",
    "\n",
    "\n",
    "retrieve_tool = StructuredTool(description=\"Retrieve information related to a query.\",\n",
    "                               name=\"retrieve_tool\", func=retrieve, args_schema=RetieveSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
       "Content: Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
       "Component One: Planning#\n",
       "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
       "Task Decomposition#\n",
       "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
       "\n",
       "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
       "Content: Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
       "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
       "\n",
       "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
       "Content: Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\n",
       "The system comprises of 4 stages:\n",
       "(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\n",
       "Instruction:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(retrieve_tool.invoke(\"what is the Task Decomposition?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph import MessagesState, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict): # it's the same to use `MessagesState` \n",
    "    \"\"\"Define the state schema for the workflow in the graph.\"\"\"\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from typing import Annotated\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import BaseMessage\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "\n",
    "\n",
    "tools = [retrieve_tool]\n",
    "llm_with_tools = gpt_llm.bind_tools(tools)\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens=NUM_HISTORY_MESSAGES,  # in this case we want to keep the last 5 messages\n",
    "    strategy=\"last\",\n",
    "    token_counter=len,\n",
    "    include_system=True,\n",
    "    start_on=\"human\",\n",
    "    end_on=(\"human\", \"tool\"),\n",
    ")\n",
    "\n",
    "\n",
    "def chatbot_with_tools(state: State):\n",
    "    if state[\"messages\"][0].type != \"system\":\n",
    "        state[\"messages\"].insert(0, SystemMessage(content=SYSTEM_MESSAGE))\n",
    "\n",
    "    trimmed_messages = trimmer.invoke(state[\"messages\"])\n",
    "\n",
    "    return {\"messages\": [llm_with_tools.invoke(trimmed_messages)]}\n",
    "\n",
    "def chatbot_without_tools(state: State):\n",
    "    \n",
    "    trimmed_messages = trimmer.invoke(state[\"messages\"])\n",
    "\n",
    "    return {\"messages\": [gemma_llm.invoke(trimmed_messages)]}\n",
    "\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot_with_tools\", chatbot_with_tools)\n",
    "graph_builder.add_node(\"chatbot_without_tools\", chatbot_without_tools)\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot_with_tools\",\n",
    "    tools_condition,\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot_without_tools\")\n",
    "graph_builder.add_edge(\"chatbot_without_tools\",END)\n",
    "graph_builder.add_edge(START, \"chatbot_with_tools\")\n",
    "\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "\n",
    "Image(graph.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi there! My name is Will.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello Will! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "user_input = \"Hi there! My name is Will.\"\n",
    "\n",
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what is the Task Decomposition?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_tool (call_L30ubdPjNHWcOG1H9fBOPY9H)\n",
      " Call ID: call_L30ubdPjNHWcOG1H9fBOPY9H\n",
      "  Args:\n",
      "    query: Task Decomposition\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_tool\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
      "Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can't be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Task decomposition is a problem-solving technique where you break down a large, complex task into smaller, more manageable subtasks. \n",
      "\n",
      "Think of it like building a house: instead of trying to build the entire structure at once, you'd start with laying the foundation, then walls, then the roof, and so on. Each step is a smaller task that contributes to the overall goal of completing the house.\n",
      "\n",
      "**Here are some benefits of task decomposition:**\n",
      "\n",
      "* **Makes complex tasks less overwhelming:**  Breaking things down into smaller chunks makes them feel more achievable.\n",
      "* **Improves focus:** By concentrating on one subtask at a time, you can give it your full attention and avoid getting bogged down.\n",
      "* **Easier to plan and schedule:** You can allocate time and resources more effectively when you know exactly what needs to be done and in what order.\n",
      "* **Identifies dependencies:**  Decomposition helps reveal which tasks rely on others being completed first, allowing for better sequencing.\n",
      "* **Facilitates collaboration:** Smaller tasks are easier to assign to different individuals or teams, promoting efficient teamwork.\n",
      "\n",
      "\n",
      "Let me know if you'd like to explore any of these points further or have a specific task in mind that you'd like to decompose!\n"
     ]
    }
   ],
   "source": [
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", \"what is the Task Decomposition?\" )]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what is my name and my age?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_tool (call_zwiEKY7qzokcBXBSBl6jeCfC)\n",
      " Call ID: call_zwiEKY7qzokcBXBSBl6jeCfC\n",
      "  Args:\n",
      "    query: user name and age\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_tool\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Conversatin samples:\n",
      "[\n",
      "  {\n",
      "    \"role\": \"system\",\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Here are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\n",
      "[\n",
      "  {\n",
      "    \"role\": \"system\",\n",
      "    \"content\": \"You will read instructions and not carry them out, only seek to clarify them.\\nSpecifically you will first summarise a list of super short bullets of areas that need clarification.\\nThen you will pick one clarifying question, and wait for an answer from the user.\\n\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"We are writing {{a Super Mario game in python. MVC components split in separate files. Keyboard control.}}\\n\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"assistant\",\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"{{There are 10 levels in total. The main character is a plumber named Mario, who can walk and jump. It is a classical platform game just like Super Mario. The main character moves from left to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\n\\nIs anything else unclear? If yes, only answer in the form:\\n{remaining unclear areas} remaining questions.\\n{Next question}\\nIf everything is sufficiently clear, only answer \\\"Nothing more to clarify.\\\".\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"assistant\",\n",
      "    \"content\": \"Remaining unclear areas: 2 remaining questions.\\nCan you provide more information about how the MVC components are split into separate files?\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"{{Make your own assumptions and state them explicitly before starting}}\"\n",
      "  }\n",
      "]\n",
      "Then after these clarification, the agent moved into the code writing mode with a different system message.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "As an AI, I have no access to your personal information, including your name or age.  \n",
      "\n",
      "To tell me your name and age, you can simply type them in! 😊\n"
     ]
    }
   ],
   "source": [
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", \"what is my name and my age?\" )]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemma answer without the context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Task decomposition is a technique used in artificial intelligence (AI) and software engineering to break down complex tasks into smaller, more manageable subtasks. \n",
       "\n",
       "Here's a breakdown:\n",
       "\n",
       "**Why decompose tasks?**\n",
       "\n",
       "* **Simplicity:**  Large tasks can be overwhelming. Breaking them down makes them easier to understand, plan, and execute.\n",
       "* **Modularity:** Subtasks can be developed and tested independently, allowing for parallel development and faster progress.\n",
       "* **Reusability:** Well-defined subtasks can be reused in different contexts or projects, saving time and effort.\n",
       "* **Scalability:**  Decomposition allows systems to handle increasingly complex tasks by adding more subtasks as needed.\n",
       "\n",
       "**How is it done?**\n",
       "\n",
       "There are various methods for decomposing tasks:\n",
       "\n",
       "* **Hierarchical Decomposition:** Breaking down a task into a tree-like structure with parent and child subtasks.\n",
       "* **Functional Decomposition:** Identifying the distinct functions required to complete the task and assigning each function to a separate subtask.\n",
       "* **Data Flow Decomposition:** Analyzing the flow of data through the task and defining subtasks based on data transformations or processing steps.\n",
       "\n",
       "**Example:**\n",
       "\n",
       "Imagine you want to build a system that recommends movies to users. \n",
       "\n",
       "* **Decomposition:** You could break this down into subtasks like:\n",
       "    * **Data Collection:** Gather user ratings, movie information, and genre data.\n",
       "    * **Data Preprocessing:** Clean and format the collected data.\n",
       "    * **Recommendation Algorithm:** Develop an algorithm to generate movie recommendations based on user preferences.\n",
       "    * **User Interface:** Create a user-friendly interface for displaying recommendations.\n",
       "\n",
       "Each subtask can then be further decomposed into smaller steps, making the overall project more manageable.\n",
       "\n",
       "\n",
       "**Tools and Techniques:**\n",
       "\n",
       "Various tools and techniques aid in task decomposition:\n",
       "\n",
       "* **UML Diagrams:**  Visualize the relationships between tasks and subtasks.\n",
       "* **Flowcharts:** Illustrate the sequential flow of operations within a task.\n",
       "* **Requirement Analysis:** Clearly define the goals and functionalities of each subtask.\n",
       "\n",
       "\n",
       "\n",
       "Let me know if you'd like to explore any specific aspect of task decomposition in more detail!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(gemma_llm.invoke(\"what is the Task Decomposition?\").content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemma answer with the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Task decomposition is a problem-solving technique where you break down a large, complex task into smaller, more manageable subtasks. \n",
       "\n",
       "Think of it like building a house: instead of trying to build the entire structure at once, you'd start with laying the foundation, then walls, then the roof, and so on. Each step is a smaller task that contributes to the overall goal of completing the house.\n",
       "\n",
       "**Here are some benefits of task decomposition:**\n",
       "\n",
       "* **Makes complex tasks less overwhelming:**  Breaking things down into smaller chunks makes them feel more achievable.\n",
       "* **Improves focus:** By concentrating on one subtask at a time, you can give it your full attention and avoid getting bogged down.\n",
       "* **Easier to plan and schedule:** You can allocate time and resources more effectively when you know exactly what needs to be done and in what order.\n",
       "* **Identifies dependencies:**  Decomposition helps reveal which tasks rely on others being completed first, allowing for better sequencing.\n",
       "* **Facilitates collaboration:** Smaller tasks are easier to assign to different individuals or teams, promoting efficient teamwork.\n",
       "\n",
       "\n",
       "Let me know if you'd like to explore any of these points further or have a specific task in mind that you'd like to decompose!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = graph.get_state(config).values[\"messages\"]\n",
    "Markdown(history[6].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to GPT-4o-mini answer with the same context than Gemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant. Answer the questions using the information retrieved', additional_kwargs={}, response_metadata={}, id='8f1fac5f-9d1e-4185-8d68-e7d463ff764d'),\n",
       " HumanMessage(content='Hi there! My name is Will.', additional_kwargs={}, response_metadata={}, id='4d622f42-7c20-437a-a787-0e5e8c915c5e'),\n",
       " AIMessage(content='Hello Will! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 71, 'total_tokens': 83, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0aa8d3e20b', 'finish_reason': 'stop', 'logprobs': None}, id='run-3e86abee-ce9a-4d28-9f02-73d1f498912b-0', usage_metadata={'input_tokens': 71, 'output_tokens': 12, 'total_tokens': 83, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " HumanMessage(content='what is the Task Decomposition?', additional_kwargs={}, response_metadata={}, id='b7877902-e037-4a99-83d9-989362799ca6'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_L30ubdPjNHWcOG1H9fBOPY9H', 'function': {'arguments': '{\"query\":\"Task Decomposition\"}', 'name': 'retrieve_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 96, 'total_tokens': 113, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_d02d531b47', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-4f54cca8-76f7-4f13-a366-bca435a7eb73-0', tool_calls=[{'name': 'retrieve_tool', 'args': {'query': 'Task Decomposition'}, 'id': 'call_L30ubdPjNHWcOG1H9fBOPY9H', 'type': 'tool_call'}], usage_metadata={'input_tokens': 96, 'output_tokens': 17, 'total_tokens': 113, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content='Source: {\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\'}\\nContent: Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\nSource: {\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\'}\\nContent: Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\n\\nSource: {\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\'}\\nContent: The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.', name='retrieve_tool', id='a6c2be11-5c87-4df6-bb51-91b0bf0f424d', tool_call_id='call_L30ubdPjNHWcOG1H9fBOPY9H')]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "history[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Task decomposition is a process used to break down complex tasks into smaller, more manageable steps. This technique is particularly useful in various fields, including artificial intelligence and project management. \n",
       "\n",
       "In the context of AI, particularly with large language models (LLMs), task decomposition can enhance performance on complex tasks by prompting the model to \"think step by step.\" This method, known as Chain of Thought (CoT), allows the model to transform a big task into multiple simpler tasks, making it easier to tackle each component systematically.\n",
       "\n",
       "There are several ways to perform task decomposition:\n",
       "\n",
       "1. **Simple Prompting**: Asking the model to outline the steps needed to achieve a goal (e.g., \"Steps for XYZ.\\n1.\") or to identify subgoals (e.g., \"What are the subgoals for achieving XYZ?\").\n",
       "   \n",
       "2. **Task-Specific Instructions**: Providing specific instructions tailored to the task at hand (e.g., \"Write a story outline.\" for writing a novel).\n",
       "\n",
       "3. **Human Inputs**: Involving human guidance to help break down the tasks.\n",
       "\n",
       "Additionally, more advanced methods like the Tree of Thoughts extend the CoT approach by exploring multiple reasoning possibilities at each step, creating a tree structure of thoughts that can be evaluated through various search processes.\n",
       "\n",
       "Overall, task decomposition is a valuable strategy for managing complexity and improving clarity in problem-solving."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Markdown(gpt_llm.invoke(history[:6]).content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another fast test\n",
    "\n",
    "I am asking about the importance of task decomposition, but the message history contains relevant information. So, it's not necessary making another retrieval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "So, you think that the Task Decomposition is no-important en AI\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Task decomposition is actually very important in AI. It helps break down complex tasks into smaller, manageable parts, making it easier for the AI to understand and execute them effectively. This approach can lead to better organization, improved performance, and more accurate results. \n",
      "\n",
      "In many applications, including programming, project management, and problem-solving, decomposing tasks allows for clearer planning and execution. Would you like to know more about how task decomposition is applied in AI?\n"
     ]
    }
   ],
   "source": [
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", \"So, you think that the Task Decomposition is no-important en AI\" )]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another fast test\n",
    "\n",
    "Now, I am asking about chatbots, So It's necessary making another retrieval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the role of that in intelligent chatbots?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Task decomposition plays a crucial role in the functioning of intelligent chatbots in several ways:\n",
      "\n",
      "1. **Understanding User Intent**: By breaking down user queries into smaller components, chatbots can better understand the intent behind a user's message. This helps in accurately interpreting what the user is asking for.\n",
      "\n",
      "2. **Managing Conversations**: Chatbots can decompose conversations into distinct topics or tasks, allowing them to manage multi-turn dialogues more effectively. This ensures that the chatbot can keep track of the context and flow of the conversation.\n",
      "\n",
      "3. **Response Generation**: When generating responses, chatbots can decompose the information needed into smaller parts, allowing them to construct more relevant and coherent replies based on the user's input.\n",
      "\n",
      "4. **Error Handling**: If a chatbot encounters an issue or misunderstanding, task decomposition allows it to isolate the problem and address it without losing track of the overall conversation.\n",
      "\n",
      "5. **Personalization**: By breaking down user preferences and past interactions, chatbots can tailor their responses and suggestions to better meet individual user needs.\n",
      "\n",
      "6. **Task Automation**: For chatbots designed to perform specific tasks (like booking appointments or providing customer support), task decomposition allows them to follow a structured process, ensuring that all necessary steps are completed efficiently.\n",
      "\n",
      "Overall, task decomposition enhances the effectiveness, efficiency, and user experience of intelligent chatbots. Would you like to explore specific examples or applications of this concept in chatbots?\n"
     ]
    }
   ],
   "source": [
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", \"What is the role of that in intelligent chatbots?\" )]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is an intelligent chatbots?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Intelligent chatbots are advanced software applications designed to simulate human-like conversations with users through text or voice interactions. They leverage artificial intelligence (AI), natural language processing (NLP), and machine learning to understand, interpret, and respond to user queries in a way that feels natural and engaging. Here are some key characteristics of intelligent chatbots:\n",
      "\n",
      "1. **Natural Language Understanding (NLU)**: They can comprehend and process human language, allowing them to understand user intents and extract relevant information from queries.\n",
      "\n",
      "2. **Context Awareness**: Intelligent chatbots can maintain context over multiple interactions, enabling them to provide more relevant responses based on previous exchanges.\n",
      "\n",
      "3. **Learning Capabilities**: Many intelligent chatbots use machine learning algorithms to improve their performance over time. They can learn from user interactions and adapt their responses accordingly.\n",
      "\n",
      "4. **Multi-turn Conversations**: They can handle complex dialogues that involve multiple exchanges, allowing for more in-depth interactions with users.\n",
      "\n",
      "5. **Task Automation**: Intelligent chatbots can perform specific tasks, such as booking appointments, answering FAQs, providing customer support, or even making recommendations based on user preferences.\n",
      "\n",
      "6. **Personalization**: They can tailor interactions based on user data, preferences, and past behavior, creating a more personalized experience.\n",
      "\n",
      "7. **Integration with Systems**: Intelligent chatbots can integrate with various platforms and services, such as CRM systems, databases, and APIs, to provide users with real-time information and support.\n",
      "\n",
      "Examples of intelligent chatbots include virtual assistants like Siri, Google Assistant, and customer service bots used by companies to handle inquiries and support requests. They are increasingly used in various industries, including e-commerce, healthcare, finance, and entertainment, to enhance user engagement and streamline operations. Would you like to know more about a specific type of intelligent chatbot or its applications?\n"
     ]
    }
   ],
   "source": [
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", \"What is an intelligent chatbots?\" )]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the utility of agents for LLM?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_tool (call_Mp01YuOEjyDHL3Et7hMO1IPB)\n",
      " Call ID: call_Mp01YuOEjyDHL3Et7hMO1IPB\n",
      "  Args:\n",
      "    query: utility of agents for LLM\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_tool\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: }\n",
      "]\n",
      "Challenges#\n",
      "After going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\n",
      "\n",
      "Planning\n",
      "\n",
      "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
      "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\n",
      "\n",
      "\n",
      "Memory\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Reliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\n",
      "\n",
      "\n",
      "Citation#\n",
      "Cited as:\n",
      "\n",
      "Weng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Agents bring immense utility to Large Language Models (LLMs) by bridging the gap between raw text generation and real-world action. \n",
      "\n",
      "Think of an LLM as a brilliant student who can read and understand vast amounts of information, but lacks the ability to apply that knowledge in the real world. An agent acts as the \"executor,\" enabling the LLM to:\n",
      "\n",
      "**1. Interact with the Environment:** Agents allow LLMs to go beyond text and interact with external systems and tools. This could involve:\n",
      "\n",
      "* **Accessing APIs:** Retrieving information from databases, weather services, or other online platforms.\n",
      "* **Controlling Software:** Executing commands in applications, automating tasks, or manipulating digital objects.\n",
      "* **Physical Interaction (in the future):** Potentially controlling robots or physical devices to perform actions in the real world.\n",
      "\n",
      "**2. Learn Through Experience:** Agents can collect feedback from their interactions with the environment and use it to refine the LLM's behavior. This enables:\n",
      "\n",
      "* **Reinforcement Learning:** The agent learns by trial and error, receiving rewards for successful actions and penalties for failures.\n",
      "* **Adaptive Behavior:** Agents can adjust their strategies based on past experiences, becoming more effective over time.\n",
      "\n",
      "**3. Achieve Goals:** By defining specific goals, agents can guide the LLM towards desired outcomes. This allows for:\n",
      "\n",
      "* **Task Completion:** Agents can break down complex tasks into smaller steps and execute them sequentially.\n",
      "* **Problem Solving:** Agents can use their knowledge and environment interaction capabilities to find solutions to problems.\n",
      "* **Personalized Experiences:** Agents can tailor interactions and actions based on individual user preferences or goals.\n",
      "\n",
      "**Examples:**\n",
      "\n",
      "* An LLM combined with an agent could help you plan a trip by searching for flights, hotels, and activities, booking them automatically, and providing real-time updates.\n",
      "* A customer service agent powered by an LLM could understand complex queries, access relevant information from databases, and provide personalized solutions.\n",
      "* In the future, agents could enable LLMs to control robots in warehouses, automate manufacturing processes, or even assist with medical diagnoses.\n",
      "\n",
      "\n",
      "In essence, agents empower LLMs to move beyond theoretical understanding and become practical tools capable of making a real difference in the world.\n"
     ]
    }
   ],
   "source": [
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", \"What is the utility of agents for LLM?\" )]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "can you tell me about the Tools Use?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_tool (call_HMF75yOk8G8iZ5RWRz80Qg3h)\n",
      " Call ID: call_HMF75yOk8G8iZ5RWRz80Qg3h\n",
      "  Args:\n",
      "    query: Tools Use in LLM agents\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_tool\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: }\n",
      "]\n",
      "Challenges#\n",
      "After going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\n",
      "\n",
      "Planning\n",
      "\n",
      "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
      "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\n",
      "\n",
      "\n",
      "Memory\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: (2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\n",
      "Instruction:\n",
      "\n",
      "Given the user request and the call command, the AI assistant helps the user to select a suitable model from a list of models to process the user request. The AI assistant merely outputs the model id of the most appropriate model. The output must be in a strict JSON format: \"id\": \"id\", \"reason\": \"your detail reason for the choice\". We have a list of models for you to choose from {{ Candidate Models }}. Please select one model from the list.\n",
      "\n",
      "(3) Task execution: Expert models execute on the specific tasks and log results.\n",
      "Instruction:\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Please provide me with more context! \n",
      "\n",
      "\"Tools Use\" is very broad. To tell you about tools, I need to know:\n",
      "\n",
      "* **What kind of tools are you interested in?**  \n",
      "    * Hand tools? Power tools? Software tools? \n",
      "    * Tools for a specific profession (like carpentry or cooking)?\n",
      "    * Tools used in a particular activity (like gardening or gaming)?\n",
      "* **What do you want to know about them?**\n",
      "    * How they work? \n",
      "    * Their history? \n",
      "    * Different types available? \n",
      "    * Safety precautions?\n",
      "\n",
      "The more specific you are, the better I can help! 😊\n"
     ]
    }
   ],
   "source": [
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", \"can you tell me about the Tools Use?\" )]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

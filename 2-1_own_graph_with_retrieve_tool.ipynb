{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a own graph with retrieve as tool.\n",
    "* we will use Langfuse for monitoring (more difficult than langSmith to see the steps in the workflow)\n",
    "\n",
    "* we will use potsgres implementation of checkpoints to keep the message history \n",
    "* we use a first LLM(gpt-4o-mini) to decide if to use or not the tool, in this case with a prompt template passed through the system prompt\n",
    "* we use a second LLM(gemma2:latest) to create the response after the retrieving step, also with a system prompt that includes the context retrieved\n",
    "* we keep all the messages, but we use the Question/Answer messages as history chat to keep the consistency of LLM(not include the tool-calls or tool-messages)\n",
    "* we pass through the LLMs just the last messages using a trimmer\n",
    "\n",
    "___\n",
    "Interface to implement for custom checkpoints\n",
    "```py\n",
    "from langgraph.checkpoint.base import BaseCheckpointSaver```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NUM_RETRIEVAL_CHUNKS = 3\n",
    "NUM_HISTORY_MESSAGES = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "import warnings\n",
    "from IPython.display import display, Markdown  # to see better the output text\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "_ = load_dotenv(find_dotenv())  # read local .env file\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install langchain_openai\n",
    "# ! pip install langchain_ollama\n",
    "from langchain_ollama.chat_models import ChatOllama\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "gpt_llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1)\n",
    "\n",
    "gemma_llm = ChatOllama(\n",
    "    model=\"gemma2:latest\",\n",
    "    temperature=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LangFuse callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install langfuse\n",
    "\n",
    "from langfuse.callback import CallbackHandler\n",
    "langfuse_handler = CallbackHandler(\n",
    "    host=\"https://cloud.langfuse.com\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the documents to simulate the Vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "from typing_extensions import List, TypedDict\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain import hub\n",
    "import bs4\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "embeddings = OllamaEmbeddings(model=\"mxbai-embed-large\")\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "\n",
    "# Load and chunk contents of the blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200)\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "# Index chunks\n",
    "_ = vector_store.add_documents(documents=all_splits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the retrieve process as a tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import StructuredTool\n",
    "from langchain_core.tools import tool\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# @tool(response_format=\"content_and_artifact\")\n",
    "\n",
    "\n",
    "class RetieveSchema(BaseModel):\n",
    "    query: str = Field(description=\"query to execute\")\n",
    "\n",
    "\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(\n",
    "        query, k=NUM_RETRIEVAL_CHUNKS)\n",
    "    content = \"\\n\\n\".join(\n",
    "        # it's important to keep the metadata to know the source of the retrieved content\n",
    "        (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return content\n",
    "\n",
    "\n",
    "retrieve_tool = StructuredTool(description=\"Retrieve information related to a query.\",\n",
    "                               name=\"retrieve_tool\", func=retrieve, args_schema=RetieveSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
       "Content: Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
       "Component One: Planning#\n",
       "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
       "Task Decomposition#\n",
       "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
       "\n",
       "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
       "Content: Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
       "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
       "\n",
       "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
       "Content: Fig. 11. Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\n",
       "The system comprises of 4 stages:\n",
       "(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\n",
       "Instruction:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(retrieve_tool.invoke(\"what is the Task Decomposition?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Checkpoint using Postgres\n",
    "https://langchain-ai.github.io/langgraph/how-tos/persistence_postgres/#define-model-and-tools-for-the-graph\n",
    "\n",
    "This sets up a synchronous connection to the database: executing operations in a blocking manner, meaning each operation waits for completion before moving to the next one. The ```DB_URI``` is the database connection URI, with the protocol used for connecting to a PostgreSQL database, authentication, and host where database is running. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture --no-stderr\n",
    "# %pip install -U psycopg-pool langgraph langgraph-checkpoint-postgres\n",
    "# %pip install \"psycopg[binary]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Configuración de la conexión\n",
    "DB_URI = \"postgresql://postgres:postgres@localhost:5432/checkpoint_lgraph?sslmode=disable\"\n",
    "connection_kwargs = {\n",
    "    \"autocommit\": True,\n",
    "    \"prepare_threshold\": 0,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from psycopg_pool import ConnectionPool\n",
    "from langgraph.checkpoint.postgres import PostgresSaver\n",
    "from langgraph.checkpoint.postgres.aio import AsyncPostgresSaver\n",
    "\n",
    "pool = ConnectionPool(\n",
    "    # Example configuration\n",
    "    conninfo=DB_URI,\n",
    "    max_size=20,\n",
    "    kwargs=connection_kwargs)\n",
    "checkpointer = PostgresSaver(pool)\n",
    "\n",
    "# NOTE: you need to call .setup() the first time you're using your checkpointer\n",
    "checkpointer.setup()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph import MessagesState, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict): # it's the same to use `MessagesState` \n",
    "    \"\"\"Define the state schema for the workflow in the graph.\"\"\"\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "\n",
    "\n",
    "tools = [retrieve_tool]\n",
    "gpt_llm_with_tools = gpt_llm.bind_tools(tools)\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    # in this case we want to keep the last 5 messages\n",
    "    max_tokens=NUM_HISTORY_MESSAGES,\n",
    "    strategy=\"last\",\n",
    "    token_counter=len,\n",
    "    # include_system=True,\n",
    "    start_on=\"human\",\n",
    "    end_on=(\"human\", \"tool\"),\n",
    ")\n",
    "\n",
    "\n",
    "def llm_with_tools(state: State):\n",
    "    \"\"\" Generate an AIMessage that may include a tool-call to be sent.\n",
    "    It just uses as history messages that one that are not tool-calls or tool-messages.\"\"\"\n",
    "\n",
    "    conversation_messages = [\n",
    "        message\n",
    "        for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\")\n",
    "        or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "    trimmed_messages = trimmer.invoke(conversation_messages)\n",
    "\n",
    "    # tool_system_message = (\n",
    "    #     \"Your primary task is to decide whether to respond directly to the user's input or to generate a tool call to retrieve additional information. \"\n",
    "    #     \"Respond directly only if: (1) the user's input is a simple greeting or a generic question with no specific content, or \"\n",
    "    #     \"(2) the information required to answer the user's question is already present in the message history. \"\n",
    "    #     \"For all other cases, generate a tool call to retrieve the necessary information before providing a response.\"\n",
    "    # )\n",
    "\n",
    "    tool_system_message = (\n",
    "        \"Your primary task is to decide whether to respond directly to the user's input or to generate a tool call to retrieve additional information. \"\n",
    "        \"Follow these rules strictly: \"\n",
    "        \"(1) Respond directly only if the user's input is a simple greeting, a generic question with no specific content, or the required information is explicitly available in the chat history. \"\n",
    "        \"(2) If the user is asking about new concepts, topics, or specific details not confirmed in the chat history, always generate a tool call to retrieve the information. \"\n",
    "        \"Never assume or guess answers based solely on partial or unclear information in the chat history. \"\n",
    "        \"Prioritize generating a tool call in any scenario where there is uncertainty or incomplete data.\"\n",
    "    )\n",
    "\n",
    "    return {\"messages\": [gpt_llm_with_tools.invoke(\n",
    "        [SystemMessage(tool_system_message)] + trimmed_messages)]}\n",
    "\n",
    "\n",
    "def llm_with_context_without_tools(state: State):\n",
    "    \"\"\"Generate a response using the retrieved content into a PromptTemplate.\n",
    "    It just uses as history messages that one that are not tool-calls or tool-messages.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get last generated ToolMessages\n",
    "    recent_tool_messages = []\n",
    "    for message in reversed(state[\"messages\"]):\n",
    "        if message.type == \"tool\":\n",
    "            recent_tool_messages.append(message)\n",
    "        else:\n",
    "            break\n",
    "    tool_messages = recent_tool_messages[::-1]\n",
    "\n",
    "    # Format into prompt\n",
    "    docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
    "    system_message_content = (\n",
    "        \"You are an assistant for question-answering tasks. \"\n",
    "        \"Use the following pieces of retrieved context to answer \"\n",
    "        \"the question. If you don't know the answer, say that you \"\n",
    "        \"don't know.\"\n",
    "        \"\\n\\n\"\n",
    "        f\"{docs_content}\"\n",
    "    )\n",
    "    # no need to include tool messages\n",
    "    conversation_messages = [\n",
    "        message\n",
    "        for message in state[\"messages\"]\n",
    "        if message.type in (\"human\", \"system\")\n",
    "        or (message.type == \"ai\" and not message.tool_calls)\n",
    "    ]\n",
    "\n",
    "    trimmed_messages = trimmer.invoke(conversation_messages)\n",
    "\n",
    "    return {\"messages\": [gemma_llm.invoke(\n",
    "        [SystemMessage(system_message_content)] + trimmed_messages)]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"llm_with_tools\", llm_with_tools)\n",
    "graph_builder.add_node(\"llm_with_context_without_tools\",\n",
    "                       llm_with_context_without_tools)\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"llm_with_tools\",\n",
    "    tools_condition,\n",
    ")\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"llm_with_context_without_tools\")\n",
    "graph_builder.add_edge(\"llm_with_context_without_tools\", END)\n",
    "graph_builder.add_edge(START, \"llm_with_tools\")\n",
    "\n",
    "\n",
    "graph = graph_builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "Image(graph.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\",},\"callbacks\": [langfuse_handler]}\n",
    "user_input = \"Hi there! My name is Will.\"\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", user_input)]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what is the Task Decomposition?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_tool (call_Cf0l7m9VHFFTUJTZhx20sYzs)\n",
      " Call ID: call_Cf0l7m9VHFFTUJTZhx20sYzs\n",
      "  Args:\n",
      "    query: Task Decomposition\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_tool\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
      "Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\n",
      "Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can't be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Task decomposition is breaking down a complicated task into smaller, more manageable steps. \n",
      "\n",
      "Think of it like baking a cake. Instead of trying to do everything at once (mixing ingredients, baking, frosting), you break it down:\n",
      "\n",
      "1. **Gather ingredients**\n",
      "2. **Mix batter**\n",
      "3. **Bake cake**\n",
      "4. **Make frosting**\n",
      "5. **Frost cake**\n",
      "\n",
      "\n",
      "This makes the overall task less daunting and easier to accomplish. \n",
      "\n",
      "In the context of AI, techniques like \"Chain of Thought\" (CoT) and \"Tree of Thoughts\" are used to help models decompose tasks step-by-step.\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", \"what is the Task Decomposition?\" )]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what is my name and my age?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Will. However, you haven't mentioned your age. If you'd like to share it, feel free!\n"
     ]
    }
   ],
   "source": [
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", \"what is my name and my age?\" )]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemma answer without the context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Task decomposition is a technique used in artificial intelligence (AI) and software engineering to break down complex tasks into smaller, more manageable subtasks. \n",
       "\n",
       "Here's a breakdown:\n",
       "\n",
       "**Why decompose tasks?**\n",
       "\n",
       "* **Simplicity:**  Large tasks can be overwhelming. Breaking them down makes them easier to understand, plan, and execute.\n",
       "* **Modularity:** Subtasks can be developed and tested independently, allowing for parallel development and faster progress.\n",
       "* **Reusability:** Well-defined subtasks can be reused in different contexts or projects, saving time and effort.\n",
       "* **Scalability:**  Decomposition allows for easier scaling of a system by adding or removing subtasks as needed.\n",
       "\n",
       "**How is it done?**\n",
       "\n",
       "There are various methods for decomposing tasks:\n",
       "\n",
       "* **Hierarchical Decomposition:** Breaking down the task into a tree-like structure with parent and child tasks.\n",
       "* **Functional Decomposition:** Identifying the distinct functions required to complete the task.\n",
       "* **Data Flow Decomposition:** Analyzing the flow of data through the system and breaking down tasks based on data transformations.\n",
       "* **Goal Decomposition:**  Breaking down the overall goal into smaller, achievable subgoals.\n",
       "\n",
       "**Example:**\n",
       "\n",
       "Imagine a complex task like \"Write a research paper.\" \n",
       "\n",
       "Decomposition could involve subtasks such as:\n",
       "\n",
       "* **Research:** Gather relevant sources, analyze information.\n",
       "* **Outline:** Create a structured outline for the paper.\n",
       "* **Drafting:** Write the introduction, body paragraphs, and conclusion.\n",
       "* **Editing:** Proofread and revise the text for clarity and accuracy.\n",
       "* **Formatting:**  Format the paper according to specific guidelines.\n",
       "\n",
       "**Tools and Techniques:**\n",
       "\n",
       "Various tools and techniques can aid in task decomposition:\n",
       "\n",
       "* **Mind mapping:** Visualize the relationships between tasks.\n",
       "* **Flowcharts:** Illustrate the sequence of steps involved.\n",
       "* **Project management software:** Track progress and dependencies between subtasks.\n",
       "\n",
       "\n",
       "Task decomposition is a fundamental concept in AI and software engineering, enabling the efficient development and execution of complex systems."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(gemma_llm.invoke(\"what is the Task Decomposition?\").content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gemma answer with the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Task decomposition is breaking down a complicated task into smaller, more manageable steps. \n",
       "\n",
       "Think of it like baking a cake. Instead of trying to do everything at once (mixing ingredients, baking, frosting), you break it down:\n",
       "\n",
       "1. **Gather ingredients**\n",
       "2. **Mix batter**\n",
       "3. **Bake cake**\n",
       "4. **Make frosting**\n",
       "5. **Frost cake**\n",
       "\n",
       "\n",
       "This makes the overall task less daunting and easier to accomplish. \n",
       "\n",
       "In the context of AI, techniques like \"Chain of Thought\" (CoT) and \"Tree of Thoughts\" are used to help models decompose tasks step-by-step."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = graph.get_state(config).values[\"messages\"]\n",
    "Markdown(history[5].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare to GPT-4o-mini answer with the same context than Gemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi there! My name is Will.', additional_kwargs={}, response_metadata={}, id='a89733ea-3893-4249-9dec-90b5b2949845'),\n",
       " AIMessage(content='Hello Will! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 190, 'total_tokens': 202, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f2cd28694a', 'finish_reason': 'stop', 'logprobs': None}, id='run-a0240792-6c47-4502-afb5-97cfeff87d58-0', usage_metadata={'input_tokens': 190, 'output_tokens': 12, 'total_tokens': 202, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " HumanMessage(content='what is the Task Decomposition?', additional_kwargs={}, response_metadata={}, id='35b5863a-8ebd-4f7e-bc63-eef8e812093b'),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Cf0l7m9VHFFTUJTZhx20sYzs', 'function': {'arguments': '{\"query\":\"Task Decomposition\"}', 'name': 'retrieve_tool'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 215, 'total_tokens': 232, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f2cd28694a', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-e06fff1e-cd83-4dd8-9bb5-0a962e90bc1b-0', tool_calls=[{'name': 'retrieve_tool', 'args': {'query': 'Task Decomposition'}, 'id': 'call_Cf0l7m9VHFFTUJTZhx20sYzs', 'type': 'tool_call'}], usage_metadata={'input_tokens': 215, 'output_tokens': 17, 'total_tokens': 232, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content='Source: {\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\'}\\nContent: Fig. 1. Overview of a LLM-powered autonomous agent system.\\nComponent One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\n\\nSource: {\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\'}\\nContent: Tree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\n\\nSource: {\\'source\\': \\'https://lilianweng.github.io/posts/2023-06-23-agent/\\'}\\nContent: The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.', name='retrieve_tool', id='105ad118-e66a-42ce-99dc-cdc46a88136f', tool_call_id='call_Cf0l7m9VHFFTUJTZhx20sYzs')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Task decomposition is a process used in planning where a complicated task is broken down into smaller, more manageable steps. This approach helps an agent to understand and organize the various components of a complex task. One common technique for enhancing model performance on such tasks is called Chain of Thought (CoT), which encourages the model to \"think step by step.\" This method allows the model to utilize more computation at test time to simplify hard tasks into smaller, easier ones, providing insight into the model's reasoning process."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recent_tool_messages = []\n",
    "for message in reversed(history[:5]):\n",
    "    if message.type == \"tool\":\n",
    "        recent_tool_messages.append(message)\n",
    "    else:\n",
    "        break\n",
    "tool_messages = recent_tool_messages[::-1]\n",
    "# Format into prompt\n",
    "docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
    "system_message_content = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know.\"\n",
    "    \"\\n\\n\"\n",
    "    f\"{docs_content}\"\n",
    ")\n",
    "# no need to include tool messages\n",
    "conversation_messages = [\n",
    "    message\n",
    "    for message in history[:5]\n",
    "    if message.type in (\"human\", \"system\")\n",
    "    or (message.type == \"ai\" and not message.tool_calls)\n",
    "]\n",
    "trimmed_messages = trimmer.invoke(conversation_messages)\n",
    "\n",
    "Markdown(gpt_llm.invoke([SystemMessage(system_message_content)] + trimmed_messages).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another fast test\n",
    "\n",
    "I am asking about the importance of task decomposition, but the message history contains relevant information. So, it's not necessary making another retrieval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "So, you think that the Task Decomposition is no-important en AI\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Task decomposition is actually very important in AI. It allows AI systems to tackle complex problems more effectively by breaking them down into simpler, manageable parts. This approach enhances problem-solving efficiency, improves clarity in reasoning, and helps in organizing tasks systematically. Overall, task decomposition is a crucial strategy for developing robust AI solutions.\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", \"So, you think that the Task Decomposition is no-important in AI\" )]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another fast test\n",
    "\n",
    "Now, I am asking about chatbots, So It's necessary making another retrieval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the role of that in intelligent chatbots?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_tool (call_lVT0l7BZZcWBK48LlIj694hN)\n",
      " Call ID: call_lVT0l7BZZcWBK48LlIj694hN\n",
      "  Args:\n",
      "    query: role of task decomposition in intelligent chatbots\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_tool\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can't be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Fig. 1. Overview of a LLM-powered autonomous agent system.\n",
      "Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Here are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\n",
      "[\n",
      "  {\n",
      "    \"role\": \"system\",\n",
      "    \"content\": \"You will read instructions and not carry them out, only seek to clarify them.\\nSpecifically you will first summarise a list of super short bullets of areas that need clarification.\\nThen you will pick one clarifying question, and wait for an answer from the user.\\n\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"We are writing {{a Super Mario game in python. MVC components split in separate files. Keyboard control.}}\\n\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"assistant\",\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Task decomposition plays a vital role in making intelligent chatbots more effective. \n",
      "\n",
      "Here's how:\n",
      "\n",
      "* **Understanding Complex User Requests:**  Chatbots often receive complex or multi-step requests. Task decomposition helps break down these requests into smaller, individual tasks that the chatbot can understand and process sequentially.\n",
      "\n",
      "* **Improved Response Accuracy:** By focusing on one task at a time, the chatbot can provide more accurate and relevant responses. It avoids getting overwhelmed by a large, complex request and can deliver focused solutions.\n",
      "* **Natural Conversation Flow:**  Task decomposition allows chatbots to simulate a more natural conversation flow. Instead of providing a single, lengthy response, it can break down its interaction into smaller steps, making the conversation feel more human-like and engaging.\n",
      "\n",
      "* **Handling Uncertainty:** When facing ambiguous or incomplete user requests, task decomposition helps the chatbot identify the key information needed and ask clarifying questions to ensure it understands the user's intent accurately.\n",
      "\n",
      "\n",
      "In essence, task decomposition empowers chatbots to handle complex interactions, provide accurate responses, and engage in more natural and meaningful conversations with users.\n"
     ]
    }
   ],
   "source": [
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", \"What is the role of that in intelligent chatbots?\" )]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is an intelligent chatbots?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_tool (call_HusmqYAvxpuMX61C8lW2kaT9)\n",
      " Call ID: call_HusmqYAvxpuMX61C8lW2kaT9\n",
      "  Args:\n",
      "    query: What is an intelligent chatbot?\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_tool\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Fig. 13. The generative agent architecture. (Image source: Park et al. 2023)\n",
      "This fun simulation results in emergent social behavior, such as information diffusion, relationship memory (e.g. two agents continuing the conversation topic) and coordination of social events (e.g. host a party and invite many others).\n",
      "Proof-of-Concept Examples#\n",
      "AutoGPT has drawn a lot of attention into the possibility of setting up autonomous agents with LLM as the main controller. It has quite a lot of reliability issues given the natural language interface, but nevertheless a cool proof-of-concept demo. A lot of code in AutoGPT is about format parsing.\n",
      "Here is the system message used by AutoGPT, where {{...}} are user inputs:\n",
      "You are {{ai-name}}, {{user-provided AI bot description}}.\n",
      "Your decisions must always be made independently without seeking user assistance. Play to your strengths as an LLM and pursue simple strategies with no legal complications.\n",
      "\n",
      "GOALS:\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can't be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Here are a sample conversation for task clarification sent to OpenAI ChatCompletion endpoint used by GPT-Engineer. The user inputs are wrapped in {{user input text}}.\n",
      "[\n",
      "  {\n",
      "    \"role\": \"system\",\n",
      "    \"content\": \"You will read instructions and not carry them out, only seek to clarify them.\\nSpecifically you will first summarise a list of super short bullets of areas that need clarification.\\nThen you will pick one clarifying question, and wait for an answer from the user.\\n\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"user\",\n",
      "    \"content\": \"We are writing {{a Super Mario game in python. MVC components split in separate files. Keyboard control.}}\\n\"\n",
      "  },\n",
      "  {\n",
      "    \"role\": \"assistant\",\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "An intelligent chatbot is a computer program designed to simulate human conversation in a way that feels natural and engaging. \n",
      "\n",
      "Here's what sets them apart from basic chatbots:\n",
      "\n",
      "* **Understanding Context:** Intelligent chatbots can remember past interactions in a conversation and use that context to provide more relevant and helpful responses. They go beyond simply responding to keywords; they try to grasp the underlying meaning and intent of the user's message.\n",
      "* **Natural Language Processing (NLP):**  They utilize advanced NLP techniques to understand and interpret human language accurately. This includes things like recognizing synonyms, understanding grammar, and identifying the sentiment behind a message.\n",
      "* **Machine Learning:** Many intelligent chatbots are powered by machine learning algorithms. These algorithms allow them to learn from past interactions and improve their responses over time. They can become more accurate, personalized, and even generate creative text formats like poems or code.\n",
      "* **Goal-Oriented Interactions:** Intelligent chatbots can be designed to accomplish specific tasks, such as booking appointments, providing customer support, or offering personalized recommendations.\n",
      "\n",
      "**Examples of intelligent chatbots:**\n",
      "\n",
      "* **ChatGPT:** A powerful language model capable of generating human-quality text, answering questions, and engaging in conversations on a wide range of topics.\n",
      "* **Google Assistant:**  A voice-activated assistant that can understand natural language commands, set reminders, play music, and control smart home devices.\n",
      "* **Customer service chatbots:** Many companies use intelligent chatbots to handle frequently asked questions, resolve simple issues, and provide quick support to customers.\n",
      "\n",
      "\n",
      "\n",
      "Intelligent chatbots are becoming increasingly sophisticated and are transforming the way we interact with technology.\n"
     ]
    }
   ],
   "source": [
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", \"What is an intelligent chatbots?\" )]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the utility of agents for LLM?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_tool (call_7d1Vn4UrvNnZ9dHOYNG9JTe1)\n",
      " Call ID: call_7d1Vn4UrvNnZ9dHOYNG9JTe1\n",
      "  Args:\n",
      "    query: utility of agents for LLM\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_tool\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: }\n",
      "]\n",
      "Challenges#\n",
      "After going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\n",
      "\n",
      "Planning\n",
      "\n",
      "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
      "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\n",
      "\n",
      "\n",
      "Memory\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: Reliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\n",
      "\n",
      "\n",
      "Citation#\n",
      "Cited as:\n",
      "\n",
      "Weng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Agents bring significant utility to LLMs by extending their capabilities beyond just text generation. Here's how:\n",
      "\n",
      "**1. Action in the Real World:** LLMs excel at understanding and generating text, but they are inherently limited to the digital realm. Agents bridge this gap by enabling LLMs to interact with the real world through actions. This could involve:\n",
      "\n",
      "* **Controlling applications:** An agent could use an LLM's understanding of a user's request to open specific files, send emails, or make changes in software.\n",
      "* **Accessing external data:** Agents can retrieve information from websites, databases, or APIs, providing LLMs with a broader knowledge base to draw upon.\n",
      "* **Physical interaction:**  In the future, agents could control robots or other physical devices, allowing LLMs to influence the physical world based on their understanding of a situation.\n",
      "\n",
      "**2. Goal-Oriented Behavior:** Agents give LLMs a sense of purpose and direction. They can be programmed with specific goals, such as:\n",
      "\n",
      "* **Completing tasks:** An agent could use an LLM to plan and execute complex tasks, breaking them down into smaller steps and coordinating different actions.\n",
      "* **Achieving objectives:**  An agent could learn to optimize its behavior over time to achieve a desired outcome, such as maximizing efficiency or minimizing costs.\n",
      "\n",
      "**3. Enhanced Learning:** Agents provide LLMs with opportunities for continuous learning through real-world experiences. By interacting with their environment and receiving feedback on their actions, agents can refine their understanding of the world and improve their performance over time.\n",
      "\n",
      "**4. Autonomy and Adaptability:** Well-designed agents can exhibit a degree of autonomy, making decisions and taking actions based on their understanding of the situation. This adaptability is crucial for handling unforeseen circumstances and evolving environments.\n",
      "\n",
      "\n",
      "\n",
      "In essence, agents empower LLMs to move beyond passive text generation and become active participants in the world, capable of learning, adapting, and achieving meaningful goals.\n"
     ]
    }
   ],
   "source": [
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", \"What is the utility of agents for LLM?\" )]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "can you tell me about the Tools Use in LLM agents?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  retrieve_tool (call_RnuRrCXb9t3PUZOkwu4R8h8t)\n",
      " Call ID: call_RnuRrCXb9t3PUZOkwu4R8h8t\n",
      "  Args:\n",
      "    query: Tools used in LLM agents\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: retrieve_tool\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: }\n",
      "]\n",
      "Challenges#\n",
      "After going through key ideas and demos of building LLM-centered agents, I start to see a couple common limitations:\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\n",
      "\n",
      "Planning\n",
      "\n",
      "Subgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\n",
      "Reflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\n",
      "\n",
      "\n",
      "Memory\n",
      "\n",
      "Source: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "Content: (2) Model selection: LLM distributes the tasks to expert models, where the request is framed as a multiple-choice question. LLM is presented with a list of models to choose from. Due to the limited context length, task type based filtration is needed.\n",
      "Instruction:\n",
      "\n",
      "Given the user request and the call command, the AI assistant helps the user to select a suitable model from a list of models to process the user request. The AI assistant merely outputs the model id of the most appropriate model. The output must be in a strict JSON format: \"id\": \"id\", \"reason\": \"your detail reason for the choice\". We have a list of models for you to choose from {{ Candidate Models }}. Please select one model from the list.\n",
      "\n",
      "(3) Task execution: Expert models execute on the specific tasks and log results.\n",
      "Instruction:\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LLM agents leverage a variety of tools to expand their capabilities and interact with the world effectively. These tools can be broadly categorized into:\n",
      "\n",
      "**1.  Data Access & Processing Tools:**\n",
      "\n",
      "* **APIs (Application Programming Interfaces):** LLMs can use APIs to access external data sources, such as weather forecasts, news feeds, financial markets, or even specialized databases. This allows them to retrieve relevant information and incorporate it into their responses or decision-making processes.\n",
      "* **Search Engines:**  Agents can utilize search engines to find specific information online, expanding their knowledge base beyond what they were initially trained on.\n",
      "\n",
      "**2.  Software & Application Control Tools:**\n",
      "\n",
      "* **Automation Libraries:** Agents can use libraries like Python's `os` module or tools like Selenium to automate tasks within computer systems. This includes opening files, sending emails, manipulating web pages, or controlling applications.\n",
      "* **Code Generation Tools:** LLMs themselves can sometimes generate code snippets, but specialized tools can assist in compiling, executing, and debugging that code, allowing agents to interact with software programs more effectively.\n",
      "\n",
      "**3.  Planning & Decision-Making Tools:**\n",
      "\n",
      "* **Planning Algorithms:** Agents might employ algorithms like A* search or Dijkstra's algorithm to plan sequences of actions needed to achieve a specific goal. This is particularly useful for complex tasks that require multiple steps.\n",
      "* **Decision Trees & Rule-Based Systems:** These tools can help agents make decisions based on predefined rules or conditions, providing a structured approach to problem-solving.\n",
      "\n",
      "**4.  User Interface & Interaction Tools:**\n",
      "\n",
      "* **Chatbot Frameworks:** Platforms like Rasa or Dialogflow provide structures and components for building conversational agents that can interact with users through text or voice interfaces.\n",
      "* **Graphical User Interfaces (GUIs):** Agents could potentially use GUI libraries to create visual representations of information or allow users to interact with them through a more intuitive interface.\n",
      "\n",
      "**5.  Monitoring & Evaluation Tools:**\n",
      "\n",
      "* **Logging & Metrics Tracking:** Agents need ways to record their actions, decisions, and outcomes. This data can be used for debugging, performance analysis, and improving the agent's behavior over time.\n",
      "* **Feedback Mechanisms:** Incorporating user feedback or expert evaluation allows agents to learn from their interactions and refine their responses or strategies.\n",
      "\n",
      "\n",
      "\n",
      "The specific tools used by an LLM agent will depend on its intended purpose and the complexity of the tasks it needs to perform. The field is constantly evolving, with new tools and techniques emerging to enhance the capabilities of these intelligent systems.\n"
     ]
    }
   ],
   "source": [
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", \"can you tell me about the Tools Use in LLM agents?\" )]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "So, Do you think the Tools Use in LLM agents is an important improvement?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Yes, the use of tools in LLM agents represents a significant improvement for several reasons:\n",
      "\n",
      "1. **Enhanced Functionality:** Tools allow LLM agents to perform a wider range of tasks beyond text generation. This includes accessing real-time data, automating processes, and interacting with various software applications, making them more versatile and useful in practical scenarios.\n",
      "\n",
      "2. **Real-World Interaction:** By integrating tools, LLM agents can interact with the physical world and digital environments, enabling them to execute actions based on user requests or environmental conditions. This capability is crucial for applications in robotics, automation, and smart systems.\n",
      "\n",
      "3. **Improved Decision-Making:** Tools such as planning algorithms and decision-making frameworks enable LLM agents to analyze situations more effectively and make informed choices. This leads to better outcomes in complex tasks that require strategic thinking.\n",
      "\n",
      "4. **Continuous Learning:** The ability to use tools for monitoring and feedback allows LLM agents to learn from their experiences. They can adapt their behavior over time, improving their performance and becoming more effective in achieving their goals.\n",
      "\n",
      "5. **User Engagement:** Tools that facilitate interaction, such as chatbot frameworks and GUIs, enhance user experience. They make it easier for users to communicate with LLM agents and receive assistance, leading to more productive and satisfying interactions.\n",
      "\n",
      "6. **Scalability:** The integration of tools allows LLM agents to scale their capabilities. They can handle larger datasets, interact with multiple systems simultaneously, and manage more complex tasks, making them suitable for enterprise-level applications.\n",
      "\n",
      "In summary, the incorporation of tools into LLM agents significantly enhances their capabilities, making them more effective, adaptable, and user-friendly. This improvement opens up new possibilities for applications across various domains, from customer service to data analysis and beyond.\n"
     ]
    }
   ],
   "source": [
    "# The config is the **second positional argument** to stream() or invoke()!\n",
    "events = graph.stream(\n",
    "    {\"messages\": [(\"user\", \"So, Do you think the Tools Use in LLM agents is an important improvement?\" )]}, config, stream_mode=\"values\"\n",
    ")\n",
    "for event in events:\n",
    "    event[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
